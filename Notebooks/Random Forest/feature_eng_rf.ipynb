{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ac8aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff69118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars version: 1.35.2\n",
      "has groupby_rolling: False\n",
      "has group_by_rolling: False\n",
      "has rolling: True\n",
      "LazyFrame has rolling: True\n"
     ]
    }
   ],
   "source": [
    "print(\"polars version:\", pl.__version__)\n",
    "print(\"has groupby_rolling:\", hasattr(pl.DataFrame, \"groupby_rolling\"))\n",
    "print(\"has group_by_rolling:\", hasattr(pl.DataFrame, \"group_by_rolling\"))\n",
    "print(\"has rolling:\", hasattr(pl.DataFrame, \"rolling\"))\n",
    "print(\"LazyFrame has rolling:\", hasattr(pl.LazyFrame, \"rolling\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ff1b3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wyk28\\AppData\\Local\\Temp\\ipykernel_27268\\1650337769.py:51: DeprecationWarning: the `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "(Deprecated in version 1.0.0)\n",
      "  .replace({\"Yes\": 1, \"No\": 0}, default=None)\n"
     ]
    }
   ],
   "source": [
    "#Clean up \n",
    "\n",
    "df = pl.read_csv(\"../../Data/raw/credit_card_transactions-ibm_v2.csv\")\n",
    "df = df.unique()\n",
    "df = df.sample(fraction=0.5, seed=42)\n",
    "df.head(n = 10)\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col(\"Merchant State\").fill_null(\"ONLINE\").alias(\"Merchant State\")\n",
    ")\n",
    "\n",
    "df = df.with_columns([\n",
    "    pl.col(\"Merchant State\").fill_null(pl.lit(\"ONLINE\")).alias(\"Merchant State\"),\n",
    "    pl.col(\"Zip\").cast(pl.Utf8).alias(\"Zip_str\"),\n",
    "])\n",
    "\n",
    "df = df.with_columns([\n",
    "    pl.col(\"Errors?\").fill_null(\"No Error\").alias(\"Errors?\")\n",
    "])\n",
    "# 2) Conditional Zip_str rules (use pl.lit for string literals)\n",
    "df = df.with_columns([\n",
    "    pl.when(pl.col(\"Merchant State\") == \"ONLINE\")\n",
    "      .then(pl.lit(\"ONLINE\"))\n",
    "      .when(pl.col(\"Zip_str\").is_null() & (pl.col(\"Merchant State\") != \"ONLINE\"))\n",
    "      .then(pl.lit(\"NON_US\"))\n",
    "      .otherwise(pl.col(\"Zip_str\"))\n",
    "      .alias(\"Zip_str\")\n",
    "])\n",
    "\n",
    "dt_expr = (\n",
    "    pl.col(\"Year\").cast(pl.Utf8)\n",
    "    + \"-\" + pl.col(\"Month\").cast(pl.Utf8).str.zfill(2)\n",
    "    + \"-\" + pl.col(\"Day\").cast(pl.Utf8).str.zfill(2)\n",
    "    + \" \" + pl.col(\"Time\").cast(pl.Utf8)\n",
    ")\n",
    "df = df.with_columns([\n",
    "    dt_expr.str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M\").alias(\"DateTime\")\n",
    "])\n",
    "\n",
    "# 5) Extract Date and Hour, build User_card, truncate Zip_str\n",
    "df = df.with_columns([\n",
    "    pl.col(\"DateTime\").dt.date().alias(\"Date\"),\n",
    "    pl.col(\"DateTime\").dt.hour().alias(\"Hour\"),\n",
    "    (pl.col(\"User\").cast(pl.Utf8) + \"_\" + pl.col(\"Card\").cast(pl.Utf8)).alias(\"User_card\"),\n",
    "    pl.col(\"Zip_str\").str.slice(0, 3).alias(\"Zip_str\"),\n",
    "])\n",
    "\n",
    "df = df.with_columns([\n",
    "    pl.col(\"Is Fraud?\")\n",
    "      .cast(pl.Utf8)\n",
    "      .replace({\"Yes\": 1, \"No\": 0}, default=None)\n",
    "      .cast(pl.Int8)               # small int is fine\n",
    "      .alias(\"Is Fraud?\")\n",
    "])\n",
    "\n",
    "df = df.with_columns([\n",
    "    pl.col(\"Amount\").cast(pl.Utf8)\n",
    "        .str.replace_all(r\"[^0-9\\.\\-]\", \"\")   \n",
    "        .replace('', None)\n",
    "        .cast(pl.Float64)                    \n",
    "        .alias(\"Amount\")\n",
    "])\n",
    "\n",
    "df = df.drop(\"Zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79c1b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_y = df.select([\n",
    "    pl.col(\"Is Fraud?\")\n",
    "])\n",
    "\n",
    "baseline_X = df.drop(\"Is Fraud?\")\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    baseline_X, baseline_y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db1da5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = pl.read_csv(\"../../Data/raw/sd254_cards.csv\")\n",
    "users = pl.read_csv(\"../../Data/raw/sd254_users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aabff0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.with_columns(\n",
    "    pl.arange(0, users.height).alias(\"User\")\n",
    ")\n",
    "\n",
    "cards = cards.with_columns([\n",
    "    (pl.col(\"User\").cast(pl.Utf8) + \"_\" + pl.col(\"CARD INDEX\").cast(pl.Utf8)).alias(\"User_card\")\n",
    "    ])\n",
    "\n",
    "users = users.select([\"State\", \"FICO Score\", \"Yearly Income - Person\", \"Total Debt\", \"Num Credit Cards\", \"User\"])\n",
    "cards = cards.select([\"User_card\", \"Card Brand\", \"Credit Limit\", \"Card on Dark Web\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "472edcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctrain_X = train_X.join(users, on=\"User\", how=\"left\").join(cards, on=\"User_card\", how=\"left\")\n",
    "Ctest_X = test_X.join(users, on=\"User\", how=\"left\").join(cards, on=\"User_card\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c625a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import List as TList\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def estimate_kappa_from_R_scalar(R: float, eps: float = 1e-12, max_kappa: float = 1e8) -> float:\n",
    "    \"\"\"\n",
    "    Robust approximation for kappa from resultant length R (R in [0,1]).\n",
    "    Avoids division by zero / numerical explosion when R -> 1 by clamping.\n",
    "    Returns a small positive value for R ~ 0 and a large finite value for R ~ 1.\n",
    "    \"\"\"\n",
    "    # sanitize input\n",
    "    if R is None or not np.isfinite(R):\n",
    "        return 1e-8\n",
    "    # clamp into [0, 1)\n",
    "    if R <= 0.0:\n",
    "        return 1e-8\n",
    "    if R >= 1.0 - eps:\n",
    "        # R extremely close to 1 -> concentration effectively infinite; return a large finite kappa\n",
    "        return float(max_kappa)\n",
    "\n",
    "    # standard approximate formulas (Mardia & Jupp / Best & Fisher)\n",
    "    if R < 0.53:\n",
    "        k = 2 * R + R**3 + (5 * R**5) / 6.0\n",
    "    elif R < 0.85:\n",
    "        k = -0.4 + 1.39 * R + 0.43 / (1.0 - R)\n",
    "    else:\n",
    "        denom = (R**3 - 4 * R**2 + 3 * R)\n",
    "        # protect denom from being tiny/zero\n",
    "        if abs(denom) < 1e-12:\n",
    "            return float(max_kappa)\n",
    "        k = 1.0 / denom\n",
    "\n",
    "    # final safety: ensure finite and positive\n",
    "    if not np.isfinite(k) or k <= 0:\n",
    "        return 1e-8\n",
    "    return float(k)\n",
    "\n",
    "def pct_last(lst):\n",
    "    if not lst:\n",
    "        return 0.0\n",
    "    last = lst[-1]\n",
    "    cnt_le = sum(1 for v in lst if v <= last)\n",
    "    return float(cnt_le) / float(len(lst))\n",
    "\n",
    "def card_stats_from_angles(angles):\n",
    "    \"\"\"\n",
    "    angles: list or 1D-array of radian angles\n",
    "    returns: (mu, R, kappa) with robust guarding\n",
    "    \"\"\"\n",
    "    if angles is None or len(angles) == 0:\n",
    "        return 0.0, 0.0, 1e-8\n",
    "    ang = np.asarray(angles, dtype=float)\n",
    "    # protect against all-nan or empty effective\n",
    "    if ang.size == 0 or not np.isfinite(ang).any():\n",
    "        return 0.0, 0.0, 1e-8\n",
    "\n",
    "    comp = np.mean(np.exp(1j * ang))\n",
    "    mu = float(np.angle(comp))\n",
    "    R = float(np.abs(comp))\n",
    "    # clamp R to [0, 1)\n",
    "    R = max(0.0, min(R, 1.0 - 1e-12))\n",
    "    kappa = estimate_kappa_from_R_scalar(R)\n",
    "    return mu, R, kappa\n",
    "\n",
    "def process_df (df):\n",
    "\n",
    "    df = df.with_columns([\n",
    "    (pl.col(\"Merchant State\") != pl.col(\"State\"))\n",
    "        .cast(pl.Int8)  # 0/1 feature (optional)\n",
    "        .alias(\"merchant_state_diff\")\n",
    "])\n",
    "\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"Amount\").cast(pl.Float64).alias(\"Amount\"),\n",
    "        (pl.col(\"Amount\") < 0).cast(pl.Int8).alias(\"amount_is_refund\"),  # useful flag\n",
    "        (\n",
    "            pl.when(pl.col(\"Amount\") == 0)\n",
    "            .then(0.0)\n",
    "            .otherwise(pl.col(\"Amount\").abs().log1p()\n",
    "                        * pl.when(pl.col(\"Amount\") < 0).then(-1.0).otherwise(1.0))\n",
    "        ).alias(\"amount_log\")  \n",
    "    ])\n",
    "\n",
    "\n",
    "    # hour angle and sin/cos\n",
    "    sec_of_day = (pl.col(\"DateTime\").dt.hour() * 3600 + pl.col(\"DateTime\").dt.minute() * 60 + pl.col(\"DateTime\").dt.second())\n",
    "    df = df.with_columns([\n",
    "        sec_of_day.alias(\"sec_of_day\"),\n",
    "        (2 * math.pi * sec_of_day / 86400.0).alias(\"hour_angle\"),\n",
    "    ])\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"hour_angle\").map_elements(lambda x: float(math.sin(x))).alias(\"hour_sin\"),\n",
    "        pl.col(\"hour_angle\").map_elements(lambda x: float(math.cos(x))).alias(\"hour_cos\"),\n",
    "    ])\n",
    "\n",
    "    # von Mises: compute card-level mu,R,kappa from angle list then broadcast\n",
    "    angles = df[\"hour_angle\"].to_list()\n",
    "    mu, R, kappa = card_stats_from_angles(angles)\n",
    "    df = df.with_columns([\n",
    "        pl.lit(mu).alias(\"card_mu\"),\n",
    "        pl.lit(R).alias(\"card_R\"),\n",
    "        pl.lit(kappa).alias(\"card_kappa\"),\n",
    "    ])\n",
    "\n",
    "    # von-mises likelihood (unnormalized)\n",
    "    df = df.with_columns([\n",
    "        pl.struct([\"card_kappa\", \"card_mu\", \"hour_angle\"]).map_elements(\n",
    "            lambda s: float(np.exp(s[\"card_kappa\"] * math.cos(s[\"hour_angle\"] - s[\"card_mu\"])))\n",
    "        ).alias(\"von_mises_likelihood_card\")\n",
    "    ])\n",
    "\n",
    "\n",
    "    # tidy up per-card\n",
    "    drop_cols = [\"card_mu\", \"card_R\", \"sec_of_day\",\"Time\"]\n",
    "    for c in drop_cols:\n",
    "        if c in df.columns:\n",
    "            df = df.drop(c)\n",
    "\n",
    "    return df\n",
    "\n",
    "Ctrain_X = process_df(Ctrain_X)\n",
    "Ctest_X = process_df(Ctest_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1972ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = Path(\"../../Data/processed/challenger_splits/rf_splits\")\n",
    "Ctrain_X.write_csv(tmp_dir / \"train_X.csv\")\n",
    "Ctest_X.write_csv(tmp_dir / \"test_X.csv\")\n",
    "train_y.write_csv(tmp_dir / \"train_y.csv\")\n",
    "test_y.write_csv(tmp_dir / \"test_y.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
